{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import tensorflow as tf\n",
    "\n",
    "# Step 1: Load your dataset (replace 'your_dataset.csv' with your actual dataset)\n",
    "df = pd.read_csv('Credit.csv')\n",
    "\n",
    "# Step 2: Data Preprocessing\n",
    "# Assume 'Income', 'Limit', 'Rating', 'Cards', 'Age', 'Education', 'Gender', 'Student', 'Married', 'Ethnicity' are your features,\n",
    "# and 'Balance' is the target variable.\n",
    "\n",
    "# Select numerical features\n",
    "numerical_features = df[['Income', 'Limit', 'Rating', 'Cards', 'Age', 'Education']]\n",
    "\n",
    "# Select categorical features\n",
    "categorical_features = df[['Gender', 'Student', 'Married', 'Ethnicity']]\n",
    "\n",
    "# One-hot encode categorical features\n",
    "encoder = OneHotEncoder(drop='first')  # Note: 'drop' parameter inside fit_transform\n",
    "categorical_encoded = encoder.fit_transform(categorical_features).toarray()\n",
    "\n",
    "# Combine numerical and encoded categorical features\n",
    "features = np.hstack((numerical_features.to_numpy(), categorical_encoded))\n",
    "\n",
    "target = df['Balance']\n",
    "\n",
    "# Step 3: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Rest of the code remains the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mani\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Build the ANN model using TensorFlow\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, input_shape=(X_train_scaled.shape[1],), activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Pandas DataFrame to NumPy arrays (removed unnecessary conversion)\n",
    "X_train_np = X_train_scaled\n",
    "y_train_np = y_train.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 422193.6562 - mse: 422193.6562 - val_loss: 531950.6250 - val_mse: 531950.6250\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 431915.0312 - mse: 431915.0312 - val_loss: 519645.0938 - val_mse: 519645.0938\n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 395793.5938 - mse: 395793.5938 - val_loss: 505609.0312 - val_mse: 505609.0312\n",
      "Epoch 4/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 359577.5312 - mse: 359577.5312 - val_loss: 489196.0625 - val_mse: 489196.0625\n",
      "Epoch 5/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 385373.0312 - mse: 385373.0312 - val_loss: 470310.8750 - val_mse: 470310.8750\n",
      "Epoch 6/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 341089.0312 - mse: 341089.0312 - val_loss: 449742.0312 - val_mse: 449742.0312\n",
      "Epoch 7/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 371707.2188 - mse: 371707.2188 - val_loss: 426034.5938 - val_mse: 426034.5938\n",
      "Epoch 8/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 352740.0625 - mse: 352740.0625 - val_loss: 400847.4375 - val_mse: 400847.4375\n",
      "Epoch 9/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 314263.0938 - mse: 314263.0938 - val_loss: 373727.3125 - val_mse: 373727.3125\n",
      "Epoch 10/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 281921.1562 - mse: 281921.1562 - val_loss: 345917.7188 - val_mse: 345917.7188\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Train the model\n",
    "model.fit(X_train_np, y_train_np, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Convert Pandas Series to NumPy arrays\n",
    "y_test_np = y_test.to_numpy()\n",
    "\n",
    "# X_test_scaled is already a NumPy array, no need for additional conversion\n",
    "X_test_np = X_test_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 281506.7188 - mse: 281506.7188  \n",
      "Test Mean Squared Error: 285940.84375\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Evaluate the model\n",
    "test_loss, test_mse = model.evaluate(X_test_np, y_test_np)\n",
    "print(f'Test Mean Squared Error: {test_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "Loan Approval Predicted: Yes\n"
     ]
    }
   ],
   "source": [
    "# Example: Make predictions (in real-time scoring)\n",
    "new_income = 50000\n",
    "new_limit = 8000\n",
    "new_rating = 700\n",
    "new_cards = 2\n",
    "new_age = 35\n",
    "new_education = 16\n",
    "new_gender = 0  # Assuming 0 for Female and 1 for Male after one-hot encoding\n",
    "new_student = 1  # Assuming 1 for Yes and 0 for No after one-hot encoding\n",
    "new_married = 0  # Assuming 0 for No and 1 for Yes after one-hot encoding\n",
    "new_ethnicity = 2  # Assuming 2 for Asian after one-hot encoding\n",
    "# Include the missing feature (you might need to adjust this based on your actual data)\n",
    "new_missing_feature = 0  # Adjust this value based on the missing feature\n",
    "\n",
    "new_data = np.array([[new_income, new_limit, new_rating, new_cards, new_age, new_education, new_gender, new_student, new_married, new_ethnicity, new_missing_feature]])\n",
    "new_data_scaled = scaler.transform(new_data)\n",
    "prediction = model.predict(new_data_scaled)\n",
    "\n",
    "# Decision support based on the prediction\n",
    "if prediction[0][0] >= 0.5:\n",
    "    print(\"Loan Approval Predicted: Yes\")\n",
    "else:\n",
    "    print(\"Loan Approval Predicted: No\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
